{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATP Tennis Data - Symmetric Raw Data\n",
    "\n",
    "\n",
    "In our feature engineering notebooks, we created a dataset for match where we left categorical columns un-encoded. Player 1 was randomly chosen to be either a winner or loser for the match so that we can have multiple classes to train our models.\n",
    "\n",
    "We created an alternate dataset, where samples were duplicated and split into 2 samples where each row would have player 1 as a winner and 2nd row would have player 1 as the loser for the same match.\n",
    "\n",
    "Hypothesis for this notebook is that there shouldn't be any significant difference in our accuracy as duplicating the data adds no new information for our models.\n",
    "\n",
    "We are going to run this dataset through our models to see what effects this has on model accuracy.\n",
    "\n",
    "NOTE: Again, we are using raw player stats and we have not encoded our categorical columns\n",
    "\n",
    "## Results from Gradient Boosting with Raw Player Data\n",
    "```\n",
    "Model Score: 0.6826468602295747\n",
    "\n",
    "ROC/AUC Score: 0.682614201415636\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Loss       0.68      0.67      0.68      7381\n",
    "         Win       0.68      0.69      0.69      7429\n",
    "\n",
    "    accuracy                           0.68     14810\n",
    "   macro avg       0.68      0.68      0.68     14810\n",
    "weighted avg       0.68      0.68      0.68     14810\n",
    "```\n",
    "\n",
    "\n",
    "# Summary of Results\n",
    "\n",
    "* All models except for KNN did slightly worse (although probably not significant). We have slightly higher recall on losses but we traded off the same amount of recall for win recalls\n",
    "* Our best accuracy score came from Gradient Boosting again\n",
    "* Because the difference in accuracy score is small, it is inconclusive whether using data from this method of feature engineering would be effective\n",
    "\n",
    "```\n",
    "Model Score: 0.6800472653612424\n",
    "\n",
    "ROC/AUC Score: 0.680048494074675\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Loss       0.68      0.68      0.68     14815\n",
    "         Win       0.68      0.68      0.68     14805\n",
    "\n",
    "    accuracy                           0.68     29620\n",
    "   macro avg       0.68      0.68      0.68     29620\n",
    "weighted avg       0.68      0.68      0.68     29620\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from util import jupyter_util as ju\n",
    "from util.model_util import ModelWrapper, RSTATE, N_JOBS, MAX_ITER, REPORT_FILE, LABEL_COL\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# date\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "DATE = datetime.now().strftime(DATE_FORMAT)\n",
    "\n",
    "\n",
    "DESCRIPTION = \"raw-sym\"\n",
    "\n",
    "# sometimes I run these notebooks via command line. Environment variable is set so we know whether we are in DEBUG mode or not\n",
    "# if you want to manually run this in DEBUG mode, change default value to True\n",
    "DEBUG = bool(os.environ.get(\"IPYNB_DEBUG\", False))\n",
    "\n",
    "if DEBUG:\n",
    "    FEATURE_FILE = f'../datasets/atp_matches_1985-2019_featuressym_test.csv'\n",
    "    ModelWrapper.REPORT_FILE = '../reports/summary-test.csv'\n",
    "    DESCRIPTION = f\"{DESCRIPTION}-test\"\n",
    "else:\n",
    "\n",
    "    FEATURE_FILE = f'../datasets/atp_matches_1985-2019_featuressym.csv'\n",
    "\n",
    "\n",
    "START_YEAR = 1998\n",
    "END_YEAR = 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8bcb2a6338b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURE_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART_YEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_YEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/0_springboard/capstone2/util/jupyter_util.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(filename, label_col, start_year, end_year, random_state, data_filter)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Shape after filtering: {features.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Features shape: {features.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone2/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2100\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone2/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1782\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         )\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = ju.get_data(FEATURE_FILE, LABEL_COL, START_YEAR, END_YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train our model\n",
    "\n",
    "lr = ModelWrapper(LogisticRegression(n_jobs = N_JOBS, verbose = 1, random_state = RSTATE),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_lr = lr.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train our model\n",
    "\n",
    "knn = ModelWrapper(KNeighborsClassifier(n_jobs = N_JOBS),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_knn = knn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train our model\n",
    "\n",
    "dt = ModelWrapper(DecisionTreeClassifier(random_state = RSTATE),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_dt = dt.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train our model\n",
    "\n",
    "rf = ModelWrapper(RandomForestClassifier(random_state=RSTATE, verbose=1),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_rf = rf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train our model\n",
    "\n",
    "gb = ModelWrapper(GradientBoostingClassifier(random_state=RSTATE, verbose=1, n_iter_no_change = 4),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_gb = gb.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ModelWrapper(AdaBoostClassifier(random_state=RSTATE),\n",
    "                  description = DESCRIPTION, \n",
    "                 data_file = FEATURE_FILE,\n",
    "                  start_year = START_YEAR,\n",
    "                  end_year = END_YEAR,\n",
    "                   X_train = X_train,\n",
    "                   y_train = y_train,\n",
    "                   X_test = X_test,\n",
    "                   y_test = y_test).fit()\n",
    "y_predict_ab = ab.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ju.plot_2d(X_test, y_predict_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Decision Tree Classifier did the best with a 92% accuracy score while KNN did the worst at about 60% (below our null hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv(ab.report_file)\n",
    "report.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "descs = report.description.unique()\n",
    "\n",
    "for desc in descs:\n",
    "    report_desc = report[report.description == desc]\n",
    "    if desc == DESCRIPTION:\n",
    "        sns.lineplot(x=\"model_name\", y=\"accuracy\", data=report_desc, label=desc, linewidth=4)\n",
    "    else:\n",
    "        sns.lineplot(x=\"model_name\", y=\"accuracy\", data=report_desc, label=desc, linewidth=0.75)\n",
    "\n",
    "a.axhline(0.65, ls='--', color='r')\n",
    "a.set_title(f\"Model Accuracy\")\n",
    "_ = a.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_report = report[(report.model_name == 'GradientBoostingClassifier') &\n",
    "                                  (report.description == DESCRIPTION)]\n",
    "mw = ModelWrapper.get_model_wrapper_from_report(current_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(mw.model, data=X_train.values)\n",
    "shap_values = explainer.shap_values(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, max_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Last Finished: {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
